{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd0f19f9-434c-49c3-b65a-1c6cd323e014",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "995cbf2b-7807-4053-a2a1-aea03d259d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 46912 entries, 0 to 46911\n",
      "Data columns (total 21 columns):\n",
      " #   Column                 Non-Null Count  Dtype         \n",
      "---  ------                 --------------  -----         \n",
      " 0   VendorID               46912 non-null  int32         \n",
      " 1   lpep_pickup_datetime   46912 non-null  datetime64[us]\n",
      " 2   lpep_dropoff_datetime  46912 non-null  datetime64[us]\n",
      " 3   store_and_fwd_flag     41343 non-null  str           \n",
      " 4   RatecodeID             41343 non-null  float64       \n",
      " 5   PULocationID           46912 non-null  int32         \n",
      " 6   DOLocationID           46912 non-null  int32         \n",
      " 7   passenger_count        41343 non-null  float64       \n",
      " 8   trip_distance          46912 non-null  float64       \n",
      " 9   fare_amount            46912 non-null  float64       \n",
      " 10  extra                  46912 non-null  float64       \n",
      " 11  mta_tax                46912 non-null  float64       \n",
      " 12  tip_amount             46912 non-null  float64       \n",
      " 13  tolls_amount           46912 non-null  float64       \n",
      " 14  ehail_fee              0 non-null      float64       \n",
      " 15  improvement_surcharge  46912 non-null  float64       \n",
      " 16  total_amount           46912 non-null  float64       \n",
      " 17  payment_type           41343 non-null  float64       \n",
      " 18  trip_type              41342 non-null  float64       \n",
      " 19  congestion_surcharge   41343 non-null  float64       \n",
      " 20  cbd_congestion_fee     46912 non-null  float64       \n",
      "dtypes: datetime64[us](2), float64(15), int32(3), str(1)\n",
      "memory usage: 7.0 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_parquet(\"green_tripdata_2025-11.parquet\")\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "79868dd4-83f5-454b-891f-ed1dc131d868",
   "metadata": {},
   "outputs": [],
   "source": [
    "november_data = (data[\n",
    "                (data['lpep_pickup_datetime'] >= '2025-11-01') & \n",
    "                (data['lpep_pickup_datetime'] <= '2025-12-01') &\n",
    "                (data['trip_distance'] <= 1)\n",
    "                ][['lpep_pickup_datetime', 'trip_distance']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "63205a33-8524-467d-8fe5-ec5489d4e544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lpep_pickup_datetime    8007\n",
       "trip_distance           8007\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "november_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "99531fcd-0ef5-487f-8d8d-e312467e9044",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['day'] = data['lpep_pickup_datetime'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5777866c-ee92-4753-94a2-79ba82e0f371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function aggregate in module pandas.core.frame:\n",
      "\n",
      "aggregate(self, func=None, axis: 'Axis' = 0, *args, **kwargs)\n",
      "    Aggregate using one or more operations over the specified axis.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    func : function, str, list or dict\n",
      "        Function to use for aggregating the data. If a function, must either\n",
      "        work when passed a DataFrame or when passed to DataFrame.apply.\n",
      "\n",
      "        Accepted combinations are:\n",
      "\n",
      "        - function\n",
      "        - string function name\n",
      "        - list of functions and/or function names, e.g. ``[np.sum, 'mean']``\n",
      "        - dict of axis labels -> functions, function names or list of such.\n",
      "    axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      "            If 0 or 'index': apply function to each column.\n",
      "            If 1 or 'columns': apply function to each row.\n",
      "    *args\n",
      "        Positional arguments to pass to `func`.\n",
      "    **kwargs\n",
      "        Keyword arguments to pass to `func`.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    scalar, Series or DataFrame\n",
      "\n",
      "        The return can be:\n",
      "\n",
      "        * scalar : when Series.agg is called with single function\n",
      "        * Series : when DataFrame.agg is called with a single function\n",
      "        * DataFrame : when DataFrame.agg is called with several functions\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    DataFrame.apply : Perform any type of operations.\n",
      "    DataFrame.transform : Perform transformation type operations.\n",
      "    DataFrame.groupby : Perform operations over groups.\n",
      "    DataFrame.resample : Perform operations over resampled bins.\n",
      "    DataFrame.rolling : Perform operations over rolling window.\n",
      "    DataFrame.expanding : Perform operations over expanding window.\n",
      "    core.window.ewm.ExponentialMovingWindow : Perform operation over exponential\n",
      "        weighted window.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    The aggregation operations are always performed over an axis, either the\n",
      "    index (default) or the column axis. This behavior is different from\n",
      "    `numpy` aggregation functions (`mean`, `median`, `prod`, `sum`, `std`,\n",
      "    `var`), where the default is to compute the aggregation of the flattened\n",
      "    array, e.g., ``numpy.mean(arr_2d)`` as opposed to\n",
      "    ``numpy.mean(arr_2d, axis=0)``.\n",
      "\n",
      "    `agg` is an alias for `aggregate`. Use the alias.\n",
      "\n",
      "    Functions that mutate the passed object can produce unexpected\n",
      "    behavior or errors and are not supported. See :ref:`gotchas.udf-mutation`\n",
      "    for more details.\n",
      "\n",
      "    A passed user-defined-function will be passed a Series for evaluation.\n",
      "\n",
      "    If ``func`` defines an index relabeling, ``axis`` must be ``0`` or ``index``.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> df = pd.DataFrame(\n",
      "    ...     [[1, 2, 3], [4, 5, 6], [7, 8, 9], [np.nan, np.nan, np.nan]],\n",
      "    ...     columns=[\"A\", \"B\", \"C\"],\n",
      "    ... )\n",
      "\n",
      "    Aggregate these functions over the rows.\n",
      "\n",
      "    >>> df.agg([\"sum\", \"min\"])\n",
      "            A     B     C\n",
      "    sum  12.0  15.0  18.0\n",
      "    min   1.0   2.0   3.0\n",
      "\n",
      "    Different aggregations per column.\n",
      "\n",
      "    >>> df.agg({\"A\": [\"sum\", \"min\"], \"B\": [\"min\", \"max\"]})\n",
      "            A    B\n",
      "    sum  12.0  NaN\n",
      "    min   1.0  2.0\n",
      "    max   NaN  8.0\n",
      "\n",
      "    Aggregate different functions over the columns and rename the index of\n",
      "    the resulting DataFrame.\n",
      "\n",
      "    >>> df.agg(x=(\"A\", \"max\"), y=(\"B\", \"min\"), z=(\"C\", \"mean\"))\n",
      "         A    B    C\n",
      "    x  7.0  NaN  NaN\n",
      "    y  NaN  2.0  NaN\n",
      "    z  NaN  NaN  6.0\n",
      "\n",
      "    Aggregate over the columns.\n",
      "\n",
      "    >>> df.agg(\"mean\", axis=\"columns\")\n",
      "    0    2.0\n",
      "    1    5.0\n",
      "    2    8.0\n",
      "    3    NaN\n",
      "    dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.DataFrame.agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0824c15d-54a1-4e3b-bdd0-bca8f0b6aab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_distance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>340912.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>184845.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>150685.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>125015.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>101966.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>82001.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>58998.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>54031.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>40515.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>33200.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20397.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>15019.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6031.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5976.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5954.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5639.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5609.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5594.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5352.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4925.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4636.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4495.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4465.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4271.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4249.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4228.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4060.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3964.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3512.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3331.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32.23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     trip_distance\n",
       "day               \n",
       "1        340912.96\n",
       "17       184845.16\n",
       "16       150685.50\n",
       "6        125015.02\n",
       "21       101966.76\n",
       "5         82001.02\n",
       "26        58998.62\n",
       "13        54031.07\n",
       "7         40515.05\n",
       "20        33200.56\n",
       "12        20397.38\n",
       "22        15019.74\n",
       "19         6031.56\n",
       "18         5976.12\n",
       "25         5954.80\n",
       "24         5639.29\n",
       "3          5609.86\n",
       "14         5594.69\n",
       "10         5352.27\n",
       "4          4925.90\n",
       "11         4636.86\n",
       "8          4495.23\n",
       "15         4465.84\n",
       "30         4271.82\n",
       "2          4249.90\n",
       "23         4228.88\n",
       "29         4060.74\n",
       "9          3964.26\n",
       "27         3512.98\n",
       "28         3331.53\n",
       "31           32.23"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(\n",
    "    data=data,\n",
    "    values=['trip_distance'],\n",
    "    index=['day'],\n",
    "    aggfunc='sum'\n",
    ").sort_values(by='trip_distance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0850ca69-a6c6-482a-b33e-3ad6f34c9167",
   "metadata": {},
   "outputs": [
    {
     "ename": "EmptyDataError",
     "evalue": "No columns to parse from file",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mEmptyDataError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m zone = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtaxi_zone_lookup.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(zone.info())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\workspace\\data-engineering-zoomcamp\\01_docker-terraform\\homework\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:873\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, skip_blank_lines, parse_dates, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m    861\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m    862\u001b[39m     dialect,\n\u001b[32m    863\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m    869\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m    870\u001b[39m )\n\u001b[32m    871\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\workspace\\data-engineering-zoomcamp\\01_docker-terraform\\homework\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:300\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    297\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    299\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m300\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    302\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    303\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\workspace\\data-engineering-zoomcamp\\01_docker-terraform\\homework\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1645\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1642\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1644\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1645\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\workspace\\data-engineering-zoomcamp\\01_docker-terraform\\homework\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1922\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1919\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m   1921\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1922\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1923\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1924\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\workspace\\data-engineering-zoomcamp\\01_docker-terraform\\homework\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:95\u001b[39m, in \u001b[36mCParserWrapper.__init__\u001b[39m\u001b[34m(self, src, **kwds)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m kwds[\u001b[33m\"\u001b[39m\u001b[33mdtype_backend\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33mpyarrow\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     93\u001b[39m     \u001b[38;5;66;03m# Fail here loudly instead of in cython after reading\u001b[39;00m\n\u001b[32m     94\u001b[39m     import_optional_dependency(\u001b[33m\"\u001b[39m\u001b[33mpyarrow\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m \u001b[38;5;28mself\u001b[39m._reader = \u001b[43mparsers\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTextReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[38;5;28mself\u001b[39m.unnamed_cols = \u001b[38;5;28mself\u001b[39m._reader.unnamed_cols\n\u001b[32m     99\u001b[39m passed_names = \u001b[38;5;28mself\u001b[39m.names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:575\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader.__cinit__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mEmptyDataError\u001b[39m: No columns to parse from file"
     ]
    }
   ],
   "source": [
    "zone = pd.read_csv(\"taxi_zone_lookup.csv\")\n",
    "print(zone.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10df62fe-0efe-4a37-9104-279ea39134e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f951d4-1e4a-4ca3-a16a-dc67dec01904",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300255a9-f411-47d1-96af-3bcb74d4b728",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
